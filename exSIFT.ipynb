{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the SIFT keypoint detector and feature descriptor error function\n",
    "This document contains an experiment in which different keypoint detector and feature descriptor combinations are used to detect and uniquely describe common points of interest in image pairs. The goal of this experiment is to explore the effects that varying the values of the different input parameters of the detector/descriptors have on the frequency of inlier matches when computing a 3D relationship between images based upon epipolar geometry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "There exists an optimal set of descriptor/detector parameters that can minimize the number of outlier match pairs computer over a set of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Design\n",
    "1. Select three image sets:\n",
    "    1. Nadir Facing Projective Camera.\n",
    "    2. Nadir Facing Fisheye Camera.\n",
    "    3. Oblique Camera.\n",
    "3. Define a bound and a step size for the different parameters.\n",
    "4. Load the images and initialize the Descriptor/Detector to the openCV initial values.\n",
    "5. For each image in the image set compute the keypoints and descriptors.\n",
    "6. For each pair of consecutive images, match corresponding keypoints.\n",
    "7. Estimate the fundamental matrix between the image pair and compute the inliers and outliers for the image pair.\n",
    "8. Sum the the number of inliers, outliers and total computed matches for the entire sequence.\n",
    "9. Select one parameter and vary it by +/- the step size.\n",
    "10. Repeat steps 5 - 9 while varying the selected parameter until it reaches the bounds.\n",
    "11. Reset the parameter to its initial value.\n",
    "12. Select a new parameter to vary and repeat 10.\n",
    "13. Perform 3 - 12 for each image type.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "To begin we import the necessary python packages including the custom built image processing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import image as im\n",
    "import matching as mt\n",
    "import imageUtility as ut\n",
    "import transforms as tn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select three image sets\n",
    "The following three image datasets are used:\n",
    "* __Nadir Facing Perspective Camera:__ Glacier images from the Sensefly eBee RTK\n",
    "* __Nadir Facing Fisheye Camera:__ Images of the Quatre Fourches River in Wood Buffalo National Park, Alberta, Canada\n",
    "* __Oblique Perspective Camera:__ Images of an office space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imageDir = {'glacier':{'dir':'/home/doopy/Documents/View3D/View3D_0_1/exp1/glacier/','ext':'.JPG'},\n",
    "            'wbnp':{'dir':'/home/doopy/Documents/View3D/View3D_0_1/exp1/wbnp/','ext':'.JPG'},\n",
    "            'desk':{'dir':'/home/doopy/Documents/View3D/View3D_0_1/exp1/glacier/','ext':'.png'}\n",
    "           }\n",
    "\n",
    "imgRange = range(1,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a bound and a step size for the different parameters\n",
    "In this experiment we will explore the following parameters:\n",
    "\n",
    "| Parameter | Description | Initial Value | Step Size | Bounds |\n",
    "| --- | --- | --- | --- | --- |\n",
    "|# Features | _desc_ | 10000| 0 | - |\n",
    "|# Octave Layers | _desc_ | 3| 1 | 1 - 5 |\n",
    "|Contrast Threshold | _desc_ | 0.04| 0.01 | 0.01 - 0.08 |\n",
    "|Edge Threshold | _desc_ | 10| 1 | 5 - 15 |\n",
    "|Sigma | _desc_ | 1.6 | 0.1 | 1.0 - 2.0 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nOctaveLayers = 3\n",
    "contrastThreshold = 0.04\n",
    "edgeThreshold = 10\n",
    "sigma = 1.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Initialize the Descriptor/Detector to the openCV initial values\n",
    "Using the image class, create an image object for each image in the image set, and compute the keypoints and feature descriptors corresponding to the initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.3 s, sys: 204 ms, total: 12.5 s\n",
      "Wall time: 10.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "imgParams = {'scale':0.15,\n",
    "          'kp':'sift',\n",
    "          'nOctaveLayers':nOctaveLayers,\n",
    "          'contrastThreshold':contrastThreshold,\n",
    "          'edgeThreshold':edgeThreshold,\n",
    "          'sigma':sigma\n",
    "         }\n",
    "\n",
    "imageSet = []\n",
    "\n",
    "for i in imgRange:\n",
    "    \n",
    "    imageSet.append(im.image(imageDir['glacier']['dir'] + str(i) + imageDir['glacier']['ext'],imgParams))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each consecutive pair of images match corresponding keypoints and compute the fundamental matrix\n",
    "Using the matching class compute the first-last approximate nearest neighbour algorithm in order to match keypoints in consecutive pairs within the image set.\n",
    "The transformation class is then used to compute the fundamental matrix between the two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** sigma ************\n",
      "*********** 1.0 ***********\n",
      "*********** 1.1 ***********\n",
      "*********** 1.2 ***********\n",
      "*********** 1.3 ***********\n",
      "*********** 1.4 ***********\n",
      "*********** 1.5 ***********\n",
      "*********** 1.6 ***********\n",
      "*********** 1.7 ***********\n",
      "*********** 1.8 ***********\n",
      "*********** 1.9 ***********\n",
      "*********** 2.0 ***********\n",
      "*********** nOctaveLayers ************\n",
      "*********** 1 ***********\n",
      "*********** 2 ***********\n",
      "*********** 3 ***********\n",
      "*********** 4 ***********\n",
      "*********** 5 ***********\n",
      "*********** contrastThreshold ************\n",
      "*********** 0.01 ***********\n",
      "*********** 0.02 ***********\n",
      "*********** 0.03 ***********\n",
      "*********** 0.04 ***********\n",
      "*********** 0.05 ***********\n",
      "*********** 0.06 ***********\n",
      "*********** 0.07 ***********\n",
      "*********** 0.08 ***********\n",
      "*********** edgeThreshold ************\n",
      "*********** 5 ***********\n",
      "*********** 6 ***********\n",
      "*********** 7 ***********\n",
      "*********** 8 ***********\n",
      "*********** 9 ***********\n",
      "*********** 10 ***********\n",
      "*********** 11 ***********\n",
      "*********** 12 ***********\n",
      "*********** 13 ***********\n",
      "*********** 14 ***********\n",
      "*********** 15 ***********\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = {'nOctaveLayers':{'step':1,'iv':1,'bdy':6},\n",
    "        'contrastThreshold':{'step':0.01,'iv':0.01,'bdy':0.09},\n",
    "        'edgeThreshold':{'step':1,'iv':5,'bdy':16},\n",
    "        'sigma':{'step':0.1,'iv':1.0,'bdy':2.1},\n",
    "         }\n",
    "\n",
    "\n",
    "results = {'nOctaveLayers':{'value':[],'inlierCount':[],'outlierCount':[]},\n",
    "        'contrastThreshold':{'value':[],'inlierCount':[],'outlierCount':[]},\n",
    "        'edgeThreshold':{'value':[],'inlierCount':[],'outlierCount':[]},\n",
    "        'sigma':{'value':[],'inlierCount':[],'outlierCount':[]},\n",
    "         }\n",
    "\n",
    "for parameter in params.keys():\n",
    "    \n",
    "    print '*********** ' + parameter + ' ************'\n",
    "    \n",
    "    imgParams = {'scale':0.15,\n",
    "          'kp':'sift',\n",
    "          'nOctaveLayers':nOctaveLayers,\n",
    "          'contrastThreshold':contrastThreshold,\n",
    "          'edgeThreshold':edgeThreshold,\n",
    "          'sigma':sigma\n",
    "         }\n",
    "\n",
    "    imgParams[parameter] = params[parameter]['iv']\n",
    "    \n",
    "    for j in np.arange(imgParams[parameter],params[parameter]['bdy'],params[parameter]['step']):\n",
    "        \n",
    "        print '*********** ' + str(j) + ' ***********'\n",
    "        \n",
    "        for img in imageSet:\n",
    "            \n",
    "            img.computeKP(imgParams)\n",
    "            \n",
    "        img1 = imageSet[0]\n",
    "        inlierSum = 0\n",
    "        outlierSum = 0\n",
    "\n",
    "        for img2 in imageSet[1:]:\n",
    "\n",
    "            F = tn.fundamental(img1,img2,imgParams)\n",
    "\n",
    "            inlierSum += F.inlierCount()\n",
    "            outlierSum += F.outlierCount()\n",
    "\n",
    "            img1 = img2   \n",
    "        \n",
    "        results[parameter]['value'].append(imgParams[parameter])\n",
    "        results[parameter]['inlierCount'].append(inlierSum)\n",
    "        results[parameter]['outlierCount'].append(outlierSum)\n",
    "        \n",
    "        imgParams[parameter] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contrastThreshold': {'inlierCount': [23466,\n",
       "   23466,\n",
       "   23210,\n",
       "   22534,\n",
       "   21361,\n",
       "   20612,\n",
       "   19261,\n",
       "   16933],\n",
       "  'outlierCount': [916, 916, 404, 517, 897, 441, 217, 683],\n",
       "  'value': [0.01,\n",
       "   0.01,\n",
       "   0.02,\n",
       "   0.029999999999999999,\n",
       "   0.040000000000000001,\n",
       "   0.050000000000000003,\n",
       "   0.060000000000000005,\n",
       "   0.069999999999999993]},\n",
       " 'edgeThreshold': {'inlierCount': [18658,\n",
       "   18658,\n",
       "   19762,\n",
       "   20555,\n",
       "   20732,\n",
       "   21330,\n",
       "   21361,\n",
       "   21826,\n",
       "   21858,\n",
       "   21786,\n",
       "   22438],\n",
       "  'outlierCount': [593, 593, 683, 647, 921, 699, 897, 579, 666, 836, 253],\n",
       "  'value': [5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]},\n",
       " 'nOctaveLayers': {'inlierCount': [8302, 8302, 16661, 21361, 24726],\n",
       "  'outlierCount': [204, 204, 151, 897, 771],\n",
       "  'value': [1, 1, 2, 3, 4]},\n",
       " 'sigma': {'inlierCount': [19190,\n",
       "   19190,\n",
       "   20898,\n",
       "   22881,\n",
       "   24331,\n",
       "   24585,\n",
       "   23955,\n",
       "   21361,\n",
       "   19733,\n",
       "   17809,\n",
       "   16160],\n",
       "  'outlierCount': [781, 781, 579, 1070, 634, 874, 429, 897, 538, 545, 586],\n",
       "  'value': [1.0,\n",
       "   1.0,\n",
       "   1.1000000000000001,\n",
       "   1.2000000000000002,\n",
       "   1.3000000000000003,\n",
       "   1.4000000000000004,\n",
       "   1.5000000000000004,\n",
       "   1.6000000000000005,\n",
       "   1.7000000000000006,\n",
       "   1.8000000000000007,\n",
       "   1.9000000000000008]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
